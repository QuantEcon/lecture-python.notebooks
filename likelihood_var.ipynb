{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab6982a",
   "metadata": {},
   "source": [
    "\n",
    "<a id='var-likelihood'></a>\n",
    "<div id=\"qe-notebook-header\" align=\"right\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" width=\"250px\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e5aae",
   "metadata": {},
   "source": [
    "# Likelihood Processes For VAR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d99e1",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Likelihood Processes For VAR Models](#Likelihood-Processes-For-VAR-Models)  \n",
    "  - [Overview](#Overview)  \n",
    "  - [VAR model setup](#VAR-model-setup)  \n",
    "  - [Likelihood ratio process](#Likelihood-ratio-process)  \n",
    "  - [Example 1: two AR(1) processes](#Example-1:-two-AR%281%29-processes)  \n",
    "  - [Example 2: bivariate VAR models](#Example-2:-bivariate-VAR-models)  \n",
    "  - [Application: Samuelson multiplier-accelerator](#Application:-Samuelson-multiplier-accelerator)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6928266",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This lecture extends our analysis of likelihood ratio processes to Vector Autoregressions (VARs).\n",
    "\n",
    "We’ll\n",
    "\n",
    "- Construct likelihood functions for VAR models  \n",
    "- Form likelihood ratio processes for comparing two VAR models  \n",
    "- Visualize the evolution of likelihood ratios over time  \n",
    "- Connect VAR likelihood ratios to the Samuelson multiplier-accelerator model  \n",
    "\n",
    "\n",
    "Our  analysis builds on concepts from:\n",
    "\n",
    "- [Likelihood Ratio Processes](https://python.quantecon.org/likelihood_ratio_process.html)  \n",
    "- [Linear State Space Models](https://python.quantecon.org/linear_models.html)  \n",
    "- [Samuelson Multiplier-Accelerator](https://python.quantecon.org/samuelson.html)  \n",
    "\n",
    "\n",
    "Let’s start by importing helpful  libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7266d1",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "from quantecon import LinearStateSpace\n",
    "import quantecon as qe\n",
    "from numba import jit\n",
    "from typing import NamedTuple, Optional, Tuple\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807d0023",
   "metadata": {},
   "source": [
    "## VAR model setup\n",
    "\n",
    "Consider a VAR model of the form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "x_{t+1} & = A x_t + C w_{t+1} \\\\\n",
    "x_0 & \\sim \\mathcal{N}(\\mu_0, \\Sigma_0) \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ x_t $ is an $ n \\times 1 $ state vector  \n",
    "- $ w_{t+1} \\sim \\mathcal{N}(0, I) $ is an $ m \\times 1 $ vector of shocks  \n",
    "- $ A $ is an $ n \\times n $ transition matrix  \n",
    "- $ C $ is an $ n \\times m $ volatility matrix  \n",
    "\n",
    "\n",
    "Let’s define the necessary data structures for the VAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9230d4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "VARModel = namedtuple('VARModel', ['A', 'C', 'μ_0', 'Σ_0',        \n",
    "                                    'CC', 'CC_inv', 'log_det_CC', \n",
    "                                    'Σ_0_inv', 'log_det_Σ_0'])\n",
    "def compute_stationary_var(A, C):\n",
    "    \"\"\"\n",
    "    Compute stationary mean and covariance for VAR model\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # Check stability\n",
    "    eigenvalues = np.linalg.eigvals(A)\n",
    "    if np.max(np.abs(eigenvalues)) >= 1:\n",
    "        raise ValueError(\"VAR is not stationary\")\n",
    "    \n",
    "    μ_0 = np.zeros(n)\n",
    "    \n",
    "    # Stationary covariance: solve discrete Lyapunov equation\n",
    "    # Σ_0 = A @ Σ_0 @ A.T + C @ C.T\n",
    "    CC = C @ C.T\n",
    "    Σ_0 = linalg.solve_discrete_lyapunov(A, CC)\n",
    "    \n",
    "    return μ_0, Σ_0\n",
    "\n",
    "def create_var_model(A, C, μ_0=None, Σ_0=None, stationary=True):\n",
    "    \"\"\"\n",
    "    Create a VAR model with parameters and precomputed matrices\n",
    "    \"\"\"\n",
    "    A = np.asarray(A)\n",
    "    C = np.asarray(C)\n",
    "    n = A.shape[0]\n",
    "    CC = C @ C.T\n",
    "    \n",
    "    if stationary:\n",
    "        μ_0_comp, Σ_0_comp = compute_stationary_var(A, C)\n",
    "    else:\n",
    "        μ_0_comp = μ_0 if μ_0 is not None else np.zeros(n)\n",
    "        Σ_0_comp = Σ_0 if Σ_0 is not None else np.eye(n)\n",
    "    \n",
    "    # Check if CC is singular\n",
    "    det_CC = np.linalg.det(CC)\n",
    "    if np.abs(det_CC) < 1e-10:\n",
    "        # Use pseudo-inverse for singular case\n",
    "        CC_inv = np.linalg.pinv(CC)\n",
    "        CC_reg = CC + 1e-10 * np.eye(CC.shape[0])\n",
    "        log_det_CC = np.log(np.linalg.det(CC_reg))\n",
    "    else:\n",
    "        CC_inv = np.linalg.inv(CC)\n",
    "        log_det_CC = np.log(det_CC)\n",
    "    \n",
    "    # Same check for Σ_0\n",
    "    det_Σ_0 = np.linalg.det(Σ_0_comp)\n",
    "    if np.abs(det_Σ_0) < 1e-10:\n",
    "        Σ_0_inv = np.linalg.pinv(Σ_0_comp)\n",
    "        Σ_0_reg = Σ_0_comp + 1e-10 * np.eye(Σ_0_comp.shape[0])\n",
    "        log_det_Σ_0 = np.log(np.linalg.det(Σ_0_reg))\n",
    "    else:\n",
    "        Σ_0_inv = np.linalg.inv(Σ_0_comp)\n",
    "        log_det_Σ_0 = np.log(det_Σ_0)\n",
    "    \n",
    "    return VARModel(A=A, C=C, μ_0=μ_0_comp, Σ_0=Σ_0_comp,\n",
    "                    CC=CC, CC_inv=CC_inv, log_det_CC=log_det_CC,\n",
    "                    Σ_0_inv=Σ_0_inv, log_det_Σ_0=log_det_Σ_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e74a27",
   "metadata": {},
   "source": [
    "### Joint distribution\n",
    "\n",
    "The joint probability distribution $ f(x_T, x_{T-1}, \\ldots, x_0) $ can be factored as:\n",
    "\n",
    "$$\n",
    "f(x_T, \\ldots, x_0) = f(x_T | x_{T-1}) f(x_{T-1} | x_{T-2}) \\cdots f(x_1 | x_0) f(x_0)\n",
    "$$\n",
    "\n",
    "Since the VAR is Markovian, $ f(x_{t+1} | x_t, \\ldots, x_0) = f(x_{t+1} | x_t) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc7107",
   "metadata": {},
   "source": [
    "### Conditional densities\n",
    "\n",
    "Given the Gaussian structure, the conditional distribution $ f(x_{t+1} | x_t) $ is Gaussian with:\n",
    "\n",
    "- Mean: $ A x_t $  \n",
    "- Covariance: $ CC' $  \n",
    "\n",
    "\n",
    "The log conditional density is\n",
    "\n",
    "\n",
    "<a id='equation-eq-cond-den'></a>\n",
    "$$\n",
    "\\log f(x_{t+1} | x_t) = -\\frac{n}{2} \\log(2\\pi) - \\frac{1}{2} \\log \\det(CC') - \\frac{1}{2} (x_{t+1} - A x_t)' (CC')^{-1} (x_{t+1} - A x_t) \\tag{24.1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107c4b6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood_transition(x_next, x_curr, model):\n",
    "    \"\"\"\n",
    "    Compute log likelihood of transition from x_curr to x_next\n",
    "    \"\"\"\n",
    "    x_next = np.atleast_1d(x_next)\n",
    "    x_curr = np.atleast_1d(x_curr)\n",
    "    n = len(x_next)\n",
    "    diff = x_next - model.A @ x_curr\n",
    "    return -0.5 * (n * np.log(2 * np.pi) + model.log_det_CC + \n",
    "                  diff @ model.CC_inv @ diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600671e5",
   "metadata": {},
   "source": [
    "The log density of the initial state is:\n",
    "\n",
    "$$\n",
    "\\log f(x_0) = -\\frac{n}{2} \\log(2\\pi) - \\frac{1}{2} \\log \\det(\\Sigma_0) - \\frac{1}{2} (x_0 - \\mu_0)' \\Sigma_0^{-1} (x_0 - \\mu_0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a7c42",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood_initial(x_0, model):\n",
    "    \"\"\"\n",
    "    Compute log likelihood of initial state\n",
    "    \"\"\"\n",
    "    x_0 = np.atleast_1d(x_0)\n",
    "    n = len(x_0)\n",
    "    diff = x_0 - model.μ_0\n",
    "    return -0.5 * (n * np.log(2 * np.pi) + model.log_det_Σ_0 + \n",
    "                  diff @ model.Σ_0_inv @ diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89989d24",
   "metadata": {},
   "source": [
    "Now let’s group the likelihood computations into a single function that computes the log likelihood of an entire path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2337440",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def log_likelihood_path(X, model):\n",
    "    \"\"\"\n",
    "    Compute log likelihood of entire path\n",
    "    \"\"\"\n",
    "\n",
    "    T = X.shape[0] - 1\n",
    "    log_L = log_likelihood_initial(X[0], model)\n",
    "    \n",
    "    for t in range(T):\n",
    "        log_L += log_likelihood_transition(X[t+1], X[t], model)\n",
    "        \n",
    "    return log_L\n",
    "\n",
    "def simulate_var(model, T, N_paths=1):\n",
    "    \"\"\"\n",
    "    Simulate paths from the VAR model\n",
    "    \"\"\"\n",
    "    n = model.A.shape[0]\n",
    "    m = model.C.shape[1]\n",
    "    paths = np.zeros((N_paths, T+1, n))\n",
    "    \n",
    "    for i in range(N_paths):\n",
    "        # Draw initial state\n",
    "        x = mvn.rvs(mean=model.μ_0, cov=model.Σ_0)\n",
    "        x = np.atleast_1d(x)\n",
    "        paths[i, 0] = x\n",
    "        \n",
    "        # Simulate forward\n",
    "        for t in range(T):\n",
    "            w = np.random.randn(m)\n",
    "            x = model.A @ x + model.C @ w\n",
    "            paths[i, t+1] = x\n",
    "            \n",
    "    return paths if N_paths > 1 else paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cdf1ca",
   "metadata": {},
   "source": [
    "## Likelihood ratio process\n",
    "\n",
    "Now let’s compute likelihood ratio processes for comparing two VAR models.\n",
    "\n",
    "For a VAR model with state vector $ x_t $, the log likelihood ratio at time $ t $ is\n",
    "\n",
    "$$\n",
    "\\ell_t = \\log \\frac{p_f(x_t | x_{t-1})}{p_g(x_t | x_{t-1})}\n",
    "$$\n",
    "\n",
    "where $ p_f $ and $ p_g $ are the conditional densities under models $ f $ and $ g $ respectively.\n",
    "\n",
    "The cumulative log likelihood ratio process is\n",
    "\n",
    "$$\n",
    "L_t = \\sum_{s=1}^{t} \\ell_s = \\sum_{s=1}^{t} \\log \\frac{p_f(x_s | x_{s-1})}{p_g(x_s | x_{s-1})}\n",
    "$$\n",
    "\n",
    "where $ p_f(x_t | x_{t-1}) $ and $ p_g(x_t | x_{t-1}) $ are given by their respective conditional densities defined in [(24.1)](#equation-eq-cond-den).\n",
    "\n",
    "Let’s write those equations in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2816f7ff",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def compute_likelihood_ratio_var(paths, model_f, model_g):\n",
    "    \"\"\"\n",
    "    Compute likelihood ratio process for VAR models\n",
    "    \"\"\"\n",
    "    if paths.ndim == 2:\n",
    "        paths = paths[np.newaxis, :]\n",
    "    \n",
    "    N_paths, T_plus_1, n = paths.shape\n",
    "    T = T_plus_1 - 1\n",
    "    log_L_ratios = np.zeros((N_paths, T+1))\n",
    "    \n",
    "    for i in range(N_paths):\n",
    "        X = paths[i]\n",
    "        \n",
    "        # Initial log likelihood ratio\n",
    "        log_L_f_0 = log_likelihood_initial(X[0], model_f)\n",
    "        log_L_g_0 = log_likelihood_initial(X[0], model_g)\n",
    "        log_L_ratios[i, 0] = log_L_f_0 - log_L_g_0\n",
    "        \n",
    "        # Recursive computation\n",
    "        for t in range(1, T+1):\n",
    "            log_L_f_t = log_likelihood_transition(X[t], X[t-1], model_f)\n",
    "            log_L_g_t = log_likelihood_transition(X[t], X[t-1], model_g)\n",
    "            \n",
    "            # Update log likelihood ratio\n",
    "            log_diff = log_L_f_t - log_L_g_t\n",
    "            \n",
    "            log_L_prev = log_L_ratios[i, t-1]\n",
    "            log_L_new = log_L_prev + log_diff\n",
    "            log_L_ratios[i, t] = log_L_new\n",
    "\n",
    "    return log_L_ratios if N_paths > 1 else log_L_ratios[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fe571c",
   "metadata": {},
   "source": [
    "## Example 1: two AR(1) processes\n",
    "\n",
    "Let’s start with a simple example comparing two univariate AR(1) processes with $ A_f = 0.8 $, $ A_g = 0.5 $, and $ C_f = 0.3 $, $ C_g = 0.4 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3c0cc",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Model f: AR(1) with persistence ρ = 0.8\n",
    "A_f = np.array([[0.8]])\n",
    "C_f = np.array([[0.3]])\n",
    "\n",
    "# Model g: AR(1) with persistence ρ = 0.5\n",
    "A_g = np.array([[0.5]])\n",
    "C_g = np.array([[0.4]])\n",
    "\n",
    "# Create VAR models\n",
    "model_f = create_var_model(A_f, C_f)\n",
    "model_g = create_var_model(A_g, C_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53551d73",
   "metadata": {},
   "source": [
    "Let’s generate 100 paths of length 200 from model $ f $ and compute the likelihood ratio processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69d408e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Simulate from model f\n",
    "T = 200\n",
    "N_paths = 100\n",
    "paths_from_f = simulate_var(model_f, T, N_paths)\n",
    "\n",
    "L_ratios_f = compute_likelihood_ratio_var(paths_from_f, model_f, model_g)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(min(20, N_paths)):\n",
    "    ax.plot(L_ratios_f[i], alpha=0.3, color='C0', lw=2)\n",
    "\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_ylabel(r'$\\log L_t$')\n",
    "ax.set_title('log likelihood ratio processes (nature = f)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f030f9fc",
   "metadata": {},
   "source": [
    "As we expected, the likelihood ratio processes goes to $ +\\infty $ as $ T $ increases, indicating that model $ f $ is chosen correctly by our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba92c3d",
   "metadata": {},
   "source": [
    "## Example 2: bivariate VAR models\n",
    "\n",
    "Now let’s consider an example with bivariate VAR models with\n",
    "\n",
    "$$\n",
    "A_f & = \\begin{bmatrix} 0.7 & 0.2 \\\\ 0.1 & 0.6 \\end{bmatrix}, \\quad C_f = \\begin{bmatrix} 0.3 & 0.1 \\\\ 0.1 & 0.3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "A_g & = \\begin{bmatrix} 0.5 & 0.3 \\\\ 0.2 & 0.5 \\end{bmatrix}, \\quad C_g = \\begin{bmatrix} 0.4 & 0.0 \\\\ 0.0 & 0.4 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b4d41",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A_f = np.array([[0.7, 0.2],\n",
    "                 [0.1, 0.6]])\n",
    "\n",
    "C_f = np.array([[0.3, 0.1],\n",
    "                 [0.1, 0.3]])\n",
    "\n",
    "A_g = np.array([[0.5, 0.3],\n",
    "                 [0.2, 0.5]])\n",
    "\n",
    "C_g = np.array([[0.4, 0.0],\n",
    "                 [0.0, 0.4]])\n",
    "\n",
    "# Create VAR models\n",
    "model2_f = create_var_model(A_f, C_f)\n",
    "model2_g = create_var_model(A_g, C_g)\n",
    "\n",
    "# Check stationarity\n",
    "print(\"model f eigenvalues:\", np.linalg.eigvals(A_f))\n",
    "print(\"model g eigenvalues:\", np.linalg.eigvals(A_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e16d22",
   "metadata": {},
   "source": [
    "Let’s generate 50 paths of length 50 from both models and compute the likelihood ratio processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b644b17",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Simulate from both models\n",
    "T = 50\n",
    "N_paths = 50\n",
    "\n",
    "paths_from_f = simulate_var(model2_f, T, N_paths)\n",
    "paths_from_g = simulate_var(model2_g, T, N_paths)\n",
    "\n",
    "# Compute likelihood ratios\n",
    "L_ratios_ff = compute_likelihood_ratio_var(paths_from_f, model2_f, model2_g)\n",
    "L_ratios_gf = compute_likelihood_ratio_var(paths_from_g, model2_f, model2_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868a185",
   "metadata": {},
   "source": [
    "We can see that for paths generated from model $ f $, the likelihood ratio processes tend to go to $ +\\infty $, while for paths from model $ g $, they tend to go to $ -\\infty $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0ceda",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "for i in range(min(20, N_paths)):\n",
    "    ax.plot(L_ratios_ff[i], alpha=0.5, color='C0', lw=2)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5, lw=2)\n",
    "ax.set_title(r'$\\log L_t$ (nature = f)')\n",
    "ax.set_ylabel(r'$\\log L_t$')\n",
    "\n",
    "ax = axes[1]\n",
    "for i in range(min(20, N_paths)):\n",
    "    ax.plot(L_ratios_gf[i], alpha=0.5, color='C1', lw=2)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5, lw=2)\n",
    "ax.set_title(r'$\\log L_t$ (nature = g)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b15d8bc",
   "metadata": {},
   "source": [
    "Let’s apply a  Neyman-Pearson frequentist  decision rule described   in [Likelihood Ratio Processes](https://python.quantecon.org/likelihood_ratio_process.html) that selects model $ f $ when $ \\log L_T \\geq 0 $ and model $ g $ when $ \\log L_T < 0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71295d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "T_values = np.arange(0, T+1)\n",
    "accuracy_f = np.zeros(len(T_values))\n",
    "accuracy_g = np.zeros(len(T_values))\n",
    "\n",
    "for i, t in enumerate(T_values):\n",
    "    # Correct selection when data from f\n",
    "    accuracy_f[i] = np.mean(L_ratios_ff[:, t] > 0)\n",
    "    # Correct selection when data from g\n",
    "    accuracy_g[i] = np.mean(L_ratios_gf[:, t] < 0)\n",
    "\n",
    "ax.plot(T_values, accuracy_f, 'C0', linewidth=2, label='accuracy (nature = f)')\n",
    "ax.plot(T_values, accuracy_g, 'C1', linewidth=2, label='accuracy (nature = g)')\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('T')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7fe8a6",
   "metadata": {},
   "source": [
    "Evidently, the accuracy approaches $ 1 $ as $ T $ increases, and it does so very quickly.\n",
    "\n",
    "Let’s also check the type I and type II errors as functions of $ T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b7e85",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def model_selection_analysis(T_values, model_f, model_g, N_sim=500):\n",
    "    \"\"\"\n",
    "    Analyze model selection performance for different sample sizes\n",
    "    \"\"\"\n",
    "    errors_f = []  # Type I errors\n",
    "    errors_g = []  # Type II errors\n",
    "    \n",
    "    for T in T_values:\n",
    "        # Simulate from model f\n",
    "        paths_f = simulate_var(model_f, T, N_sim//2)\n",
    "        L_ratios_f = compute_likelihood_ratio_var(paths_f, model_f, model_g)\n",
    "        \n",
    "        # Simulate from model g\n",
    "        paths_g = simulate_var(model_g, T, N_sim//2)\n",
    "        L_ratios_g = compute_likelihood_ratio_var(paths_g, model_f, model_g)\n",
    "        \n",
    "        # Decision rule: choose f if log L_T >= 0\n",
    "        errors_f.append(np.mean(L_ratios_f[:, -1] < 0))\n",
    "        errors_g.append(np.mean(L_ratios_g[:, -1] >= 0))\n",
    "    \n",
    "    return np.array(errors_f), np.array(errors_g)\n",
    "\n",
    "T_values = np.arange(1, 50, 1)\n",
    "errors_f, errors_g = model_selection_analysis(T_values, model2_f, model2_g, N_sim=400)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(T_values, errors_f, 'C0', linewidth=2, label='type I error')\n",
    "ax.plot(T_values, errors_g, 'C1', linewidth=2, label='type II error')\n",
    "ax.plot(T_values, 0.5 * (errors_f + errors_g), 'g--', \n",
    "linewidth=2, label='average error')\n",
    "ax.set_xlabel('$T$')\n",
    "ax.set_ylabel('error probability')\n",
    "ax.set_title('model selection errors')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae313e32",
   "metadata": {},
   "source": [
    "## Application: Samuelson multiplier-accelerator\n",
    "\n",
    "Now let’s connect to the Samuelson multiplier-accelerator model.\n",
    "\n",
    "The model consists of:\n",
    "\n",
    "- Consumption: $ C_t = \\gamma + a Y_{t-1} $ where $ a \\in (0,1) $ is the marginal propensity to consume  \n",
    "- Investment: $ I_t = b(Y_{t-1} - Y_{t-2}) $ where $ b > 0 $ is the accelerator coefficient  \n",
    "- Government spending: $ G_t = G $ (constant)  \n",
    "\n",
    "\n",
    "We have the national income identity\n",
    "\n",
    "$$\n",
    "Y_t = C_t + I_t + G_t\n",
    "$$\n",
    "\n",
    "Equations yields the second-order difference equation:\n",
    "\n",
    "$$\n",
    "Y_t = (\\gamma + G) + (a + b)Y_{t-1} - b Y_{t-2} + \\sigma \\epsilon_t\n",
    "$$\n",
    "\n",
    "With $ \\rho_1 = a + b $ and $ \\rho_2 = -b $, we have:\n",
    "\n",
    "$$\n",
    "Y_t = (\\gamma + G) + \\rho_1 Y_{t-1} + \\rho_2 Y_{t-2} + \\sigma \\epsilon_t\n",
    "$$\n",
    "\n",
    "To fit into our discussion, we write it into state-space representation.\n",
    "\n",
    "To handle the constant term properly, we use an augmented state vector $ \\mathbf{x}_t = [1, Y_t, Y_{t-1}]' $:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{t+1} = \\begin{bmatrix} \n",
    "1 \\\\ \n",
    "Y_{t+1} \\\\ \n",
    "Y_t \n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "1 & 0 & 0 \\\\\n",
    "\\gamma + G & \\rho_1 & \\rho_2 \\\\\n",
    "0 & 1 & 0 \n",
    "\\end{bmatrix} \\begin{bmatrix} \n",
    "1 \\\\ \n",
    "Y_t \\\\ \n",
    "Y_{t-1} \n",
    "\\end{bmatrix} + \\begin{bmatrix} \n",
    "0 \\\\ \n",
    "\\sigma \\\\ \n",
    "0 \n",
    "\\end{bmatrix} \\epsilon_{t+1}\n",
    "$$\n",
    "\n",
    "The observation equation extracts the economic variables:\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_t = \\begin{bmatrix} \n",
    "Y_t \\\\ \n",
    "C_t \\\\ \n",
    "I_t \n",
    "\\end{bmatrix} = \\begin{bmatrix} \n",
    "\\gamma + G & \\rho_1 & \\rho_2 \\\\\n",
    "\\gamma & a & 0 \\\\\n",
    "0 & b & -b \n",
    "\\end{bmatrix} \\begin{bmatrix} \n",
    "1 \\\\ \n",
    "Y_t \\\\ \n",
    "Y_{t-1} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This gives us:\n",
    "\n",
    "- $ Y_t = (\\gamma + G) \\cdot 1 + \\rho_1 Y_{t-1} + \\rho_2 Y_{t-2} $ (total output)  \n",
    "- $ C_t = \\gamma \\cdot 1 + a Y_{t-1} $ (consumption)  \n",
    "- $ I_t = b(Y_{t-1} - Y_{t-2}) $ (investment)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ff78e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def samuelson_to_var(a, b, γ, G, σ):\n",
    "    \"\"\"\n",
    "    Convert Samuelson model parameters to VAR form with augmented state\n",
    "    \n",
    "    Samuelson model:\n",
    "    - Y_t = C_t + I_t + G\n",
    "    - C_t = γ + a*Y_{t-1}\n",
    "    - I_t = b*(Y_{t-1} - Y_{t-2})\n",
    "    \n",
    "    Reduced form: Y_t = (γ+G) + (a+b)*Y_{t-1} - b*Y_{t-2} + σ*ε_t\n",
    "    \n",
    "    State vector is [1, Y_t, Y_{t-1}]'\n",
    "    \"\"\"\n",
    "    ρ_1 = a + b\n",
    "    ρ_2 = -b\n",
    "    \n",
    "    # State transition matrix for augmented state\n",
    "    A = np.array([[1,      0,     0],\n",
    "                  [γ + G,  ρ_1,   ρ_2],\n",
    "                  [0,      1,     0]])\n",
    "    \n",
    "    # Shock loading matrix\n",
    "    C = np.array([[0],\n",
    "                  [σ],\n",
    "                  [0]])\n",
    "    \n",
    "    # Observation matrix (extracts Y_t, C_t, I_t)\n",
    "    G_obs = np.array([[γ + G,  ρ_1,  ρ_2],   # Y_t\n",
    "                      [γ,      a,    0],     # C_t\n",
    "                      [0,      b,   -b]])    # I_t\n",
    "    \n",
    "    return A, C, G_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b96ca67",
   "metadata": {},
   "source": [
    "We define functions in the code cell below to get the initial conditions and check stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd27fa",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def get_samuelson_initial_conditions(a, b, γ, G, y_0=None, y_m1=None, \n",
    "                                    stationary_init=False):\n",
    "    \"\"\"\n",
    "    Get initial conditions for Samuelson model\n",
    "    \"\"\"\n",
    "    # Calculate steady state\n",
    "    y_ss = (γ + G) / (1 - a - b)\n",
    "    \n",
    "    if y_0 is None:\n",
    "        y_0 = y_ss\n",
    "    if y_m1 is None:\n",
    "        y_m1 = y_ss if stationary_init else y_0 * 0.95\n",
    "    \n",
    "    # Initial mean\n",
    "    μ_0 = np.array([1.0, y_0, y_m1])\n",
    "    \n",
    "    if stationary_init:\n",
    "        Σ_0 = np.array([[0,  0,    0],\n",
    "                        [0,  1,    0.5],\n",
    "                        [0,  0.5,  1]])\n",
    "    else:\n",
    "        Σ_0 = np.array([[0,  0,    0],\n",
    "                        [0,  25,   15],\n",
    "                        [0,  15,   25]])\n",
    "    \n",
    "    return μ_0, Σ_0\n",
    "\n",
    "def check_samuelson_stability(a, b):\n",
    "    \"\"\"\n",
    "    Check stability of Samuelson model and return characteristic roots\n",
    "    \"\"\"\n",
    "    ρ_1 = a + b\n",
    "    ρ_2 = -b\n",
    "\n",
    "    roots = np.roots([1, -ρ_1, -ρ_2])\n",
    "    max_abs_root = np.max(np.abs(roots))\n",
    "    is_stable = max_abs_root < 1\n",
    "    \n",
    "    # Determine type of dynamics\n",
    "    if np.iscomplex(roots[0]):\n",
    "        if max_abs_root < 1:\n",
    "            dynamics = \"Damped oscillations\"\n",
    "        else:\n",
    "            dynamics = \"Explosive oscillations\"\n",
    "    else:\n",
    "        if max_abs_root < 1:\n",
    "            dynamics = \"Smooth convergence\"\n",
    "        else:\n",
    "            if np.max(roots) > 1:\n",
    "                dynamics = \"Explosive growth\"\n",
    "            else:\n",
    "                dynamics = \"Explosive oscillations (real roots)\"\n",
    "    \n",
    "    return is_stable, roots, max_abs_root, dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c703f",
   "metadata": {},
   "source": [
    "Let’s implement it and inspect the likelihood ratio processes induced by two Samuelson models with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5536eec",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def create_samuelson_var_model(a, b, γ, G, σ, stationary_init=False,\n",
    "                               y_0=None, y_m1=None):\n",
    "    \"\"\"\n",
    "    Create a VAR model from Samuelson parameters\n",
    "    \"\"\"\n",
    "    A, C, G_obs = samuelson_to_var(a, b, γ, G, σ)\n",
    "    \n",
    "    μ_0, Σ_0 = get_samuelson_initial_conditions(\n",
    "        a, b, γ, G, y_0, y_m1, stationary_init\n",
    "    )\n",
    "    \n",
    "    # Create VAR model\n",
    "    model = create_var_model(A, C, μ_0, Σ_0, stationary=False)\n",
    "    is_stable, roots, max_root, dynamics = check_samuelson_stability(a, b)\n",
    "    info = {\n",
    "        'a': a, 'b': b, 'γ': γ, 'G': G, 'σ': σ,\n",
    "        'ρ_1': a + b, 'ρ_2': -b,\n",
    "        'steady_state': (γ + G) / (1 - a - b),\n",
    "        'is_stable': is_stable,\n",
    "        'roots': roots,\n",
    "        'max_abs_root': max_root,\n",
    "        'dynamics': dynamics\n",
    "    }\n",
    "    \n",
    "    return model, G_obs, info\n",
    "\n",
    "def simulate_samuelson(model, G_obs, T, N_paths=1):\n",
    "    \"\"\"\n",
    "    Simulate Samuelson model\n",
    "    \"\"\"\n",
    "    # Simulate state paths\n",
    "    states = simulate_var(model, T, N_paths)\n",
    "    \n",
    "    # Extract observables using G matrix\n",
    "    if N_paths == 1:\n",
    "        # Single path: states is (T+1, 3)\n",
    "        observables = (G_obs @ states.T).T\n",
    "    else:\n",
    "        # Multiple paths: states is (N_paths, T+1, 3)\n",
    "        observables = np.zeros((N_paths, T+1, 3))\n",
    "        for i in range(N_paths):\n",
    "            observables[i] = (G_obs @ states[i].T).T\n",
    "    \n",
    "    return states, observables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d8941",
   "metadata": {},
   "source": [
    "Now let’s simulate two Samuelson models with different accelerator coefficients and plot their sample paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a2426",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Model f: Higher accelerator coefficient\n",
    "a_f, b_f = 0.98, 0.9\n",
    "γ_f, G_f, σ_f = 10, 10, 0.5\n",
    "\n",
    "# Model g: Lower accelerator coefficient  \n",
    "a_g, b_g = 0.98, 0.85\n",
    "γ_g, G_g, σ_g = 10, 10, 0.5\n",
    "\n",
    "\n",
    "model_sam_f, G_obs_f, info_f = create_samuelson_var_model(\n",
    "    a_f, b_f, γ_f, G_f, σ_f, \n",
    "    stationary_init=False, \n",
    "    y_0=100, y_m1=95\n",
    ")\n",
    "\n",
    "model_sam_g, G_obs_g, info_g = create_samuelson_var_model(\n",
    "    a_g, b_g, γ_g, G_g, σ_g,\n",
    "    stationary_init=False,\n",
    "    y_0=100, y_m1=95\n",
    ")\n",
    "\n",
    "T = 50\n",
    "N_paths = 50\n",
    "\n",
    "# Get both states and observables\n",
    "states_f, obs_f = simulate_samuelson(model_sam_f, G_obs_f, T, N_paths)\n",
    "states_g, obs_g = simulate_samuelson(model_sam_g, G_obs_g, T, N_paths)\n",
    "\n",
    "output_paths_f = obs_f[:, :, 0] \n",
    "output_paths_g = obs_g[:, :, 0]\n",
    "    \n",
    "print(\"model f:\")\n",
    "print(f\"  ρ_1 = a + b = {info_f['ρ_1']:.2f}\")\n",
    "print(f\"  ρ_2 = -b = {info_f['ρ_2']:.2f}\")\n",
    "print(f\"  roots: {info_f['roots']}\")\n",
    "print(f\"  dynamics: {info_f['dynamics']}\")\n",
    "\n",
    "print(\"\\nmodel g:\")\n",
    "print(f\"  ρ_1 = a + b = {info_g['ρ_1']:.2f}\")\n",
    "print(f\"  ρ_2 = -b = {info_g['ρ_2']:.2f}\")\n",
    "print(f\"  roots: {info_g['roots']}\")\n",
    "print(f\"  dynamics: {info_g['dynamics']}\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for i in range(min(20, N_paths)):\n",
    "    ax.plot(output_paths_f[i], alpha=0.6, color='C0', linewidth=0.8)\n",
    "    ax.plot(output_paths_g[i], alpha=0.6, color='C1', linewidth=0.8)\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$Y_t$')\n",
    "ax.legend(['model f', 'model g'], loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d9276",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Compute likelihood ratios\n",
    "L_ratios_ff = compute_likelihood_ratio_var(states_f, model_sam_f, model_sam_g)\n",
    "L_ratios_gf = compute_likelihood_ratio_var(states_g, model_sam_f, model_sam_g) \n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "for i in range(min(20, N_paths)):\n",
    "    ax.plot(L_ratios_ff[i], alpha=0.5, color='C0', lw=0.8)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_title(r'$\\log L_t$ (nature = f)')\n",
    "ax.set_ylabel(r'$\\log L_t$')\n",
    "\n",
    "ax = axes[1]\n",
    "for i in range(min(20, N_paths)):\n",
    "    ax.plot(L_ratios_gf[i], alpha=0.5, color='C1', lw=0.8)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_title(r'$\\log L_t$ (nature = g)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce144c",
   "metadata": {},
   "source": [
    "In the figure on the left, data are generated by $ f $ and the likelihood ratio diverges to plus infinity.\n",
    "\n",
    "In the figure on the right, data are generated by $ g $ and the likelihood ratio diverges to negative infinity.\n",
    "\n",
    "In both cases, we applied a lower and upper threshold for the log likelihood ratio process for numerical stability since they grow unbounded very quickly.\n",
    "\n",
    "In both cases, the likelihood ratio processes eventually lead us to select the correct model."
   ]
  }
 ],
 "metadata": {
  "date": 1757638706.8299918,
  "filename": "likelihood_var.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Likelihood Processes For VAR Models"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}